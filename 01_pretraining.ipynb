{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 대형언어모델(LLM) 바닥부터 만들기\n",
    "\n",
    "[유튜브 강의 영상 링크](https://youtu.be/osv2csoHVAo)\n",
    "\n",
    "[홍정모 연구소 디스코드 링크](https://discord.com/invite/kgR9xJkbsV)\n",
    "\n",
    "[홍정모 연구소 홈페이지 링크](https://www.honglab.ai/)\n",
    "\n",
    "#### 참고 자료\n",
    "- [Andrej Karpathy 유튜브](https://www.youtube.com/andrejkarpathy)\n",
    "- [Build a Large Language Model (From Scratch)](https://www.manning.com/books/build-a-large-language-model-from-scratch)\n",
    "- [Om-Alve/smolGPT 깃헙](https://github.com/Om-Alve/smolGPT)\n",
    "- 트랜스포머 논문 - [Attention Is All You Need](https://arxiv.org/abs/1706.03762)\n",
    "- OpenAI GPT2 논문 - [Language Models are Unsupervised Multitask Learners](https://cdn.openai.com/better-language-models/language_models_are_unsupervised_multitask_learners.pdf)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 안내사항\n",
    "\n",
    "LLM의 핵심 개념을 개인 PC에서도 간단하게 실습하면서 공부할 수 있는 학습 자료입니다. 널리 알려진 교육/학술 자료들을 참고하여 쉽게 공부할 수 있도록 요약하고 정리한 것입니다. 코딩 스타일이나 활용 범위에 대해 오해 없으시길 바랍니다.\n",
    "\n",
    "윈도우11/WSL, Python 3.9.20, Pytorch 2.6, CUDA 12.6 에서 작동을 확인하였습니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 전체 과정 요약\n",
    "\n",
    "LLM 기반 AI 에이전트를 만들때는 핵심이 되는 LLM이 필요한데요, LLM을 바닥부터 만드는 경우 보다는 공개되어 있는 LLM 모델들을 가져다가 나의 용도에 맞도록 다듬어서 사용하는 것이 일반적입니다. 다만, 최근에는 LLM을 바닥부터 만드는 기술에 대한 진입장벽이 낮아지고 있어서 회사별로 필요한 LLM을 바닥부터 각자 만들어 사용하게 될 가능성도 높아지고 있습니다.\n",
    "\n",
    "LLM을 만들 때는 \n",
    "\n",
    "1. 사전훈련(pretraining)으로 일반적인 언어 능력을 가르친 후에 \n",
    "2. 미세조정(fine tuning) 단계에서 특정 업무에 적응\n",
    "\n",
    "시키는 것이 기본이 됩니다. 여기에 \n",
    "\n",
    "3. 데이터베이스(+인터넷) 검색 기능을 추가\n",
    "\n",
    "하면 지식의 범위와 정확성을 높일 수 있습니다. 사람이 생각을 거듭하여 더 깊이있는 결론을 이끌어 내듯이 LLM도 \n",
    "\n",
    "4. 내부적으로 질의를 반복하여 더 좋은 결론을 도출\n",
    "\n",
    "하도록 만들 수 있습니다.\n",
    "\n",
    "여기서는 LLM의 기본 원리를 이해하기 위해서 사전훈련 과정을 바닥부터 진행해보겠습니다. 훈련 과정의 큰 틀은 일반적인 머신러닝 절차를 따릅니다.\n",
    "\n",
    "1. 훈련 데이터 준비\n",
    "1. 데이터 로더 정의\n",
    "1. 모델 정의\n",
    "1. 훈련\n",
    "1. 결과 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 훈련 데이터 준비\n",
    "\n",
    "준비한 텍스트 파일을 읽어 들여서 정리한 후에 앞에 cleaned_가 붙은 파일 이름으로 정리합니다.\n",
    "> 예시) alice.txt &rarr; cleaned_alice.txt\n",
    "\n",
    "- 캐글 해리포터 책 - [Harry Potter Books](https://www.kaggle.com/datasets/shubhammaindola/harry-potter-books?select=02+Harry+Potter+and+the+Chamber+of+Secrets.txt)\n",
    "- 캐글 앨리스 책 - [alice.txt](https://www.kaggle.com/datasets/leelatte/alicetxt)\n",
    "- 훈련 데이터나 가중치는 제가 배포하지 않습니다. 직접 다운받거나 준비하셔야합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "harry/01 Harry Potter and the Sorcerers Stone.txt_cleaned 436000 characters\n",
      "harry/02 Harry Potter and the Chamber of Secrets.txt_cleaned 488771 characters\n",
      "harry/03 Harry Potter and the Prisoner of Azkaban.txt_cleaned 621137 characters\n",
      "harry/04 Harry Potter and the Goblet of Fire.txt_cleaned 1093670 characters\n",
      "harry/05 Harry Potter and the Order of the Phoenix.txt_cleaned 1489734 characters\n",
      "harry/06 Harry Potter and the Half-Blood Prince.txt_cleaned 982041 characters\n",
      "harry/07 Harry Potter and the Deathly Hallows.txt_cleaned 1133063 characters\n",
      "alice/alice.txt_cleaned 143225 characters\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def clean_text(filename):\n",
    "    with open(filename, 'r', encoding='utf-8') as file:\n",
    "        book_text = file.read()\n",
    "\n",
    "    cleaned_text = re.sub(r'\\n+', ' ', book_text) # 줄바꿈을 빈칸으로 변경\n",
    "    cleaned_text = re.sub(r'\\s+', ' ', cleaned_text) # 여러 빈칸을 하나의 빈칸으로\n",
    "\n",
    "    print(filename + \"_cleaned\", len(cleaned_text), \"characters\") # 글자 수 출력\n",
    "\n",
    "    with open(filename + \"_cleaned\", 'w', encoding='utf-8') as file:\n",
    "        file.write(cleaned_text)\n",
    "\n",
    "filenames_list = [\"harry/01 Harry Potter and the Sorcerers Stone.txt\", \"harry/02 Harry Potter and the Chamber of Secrets.txt\", \"harry/03 Harry Potter and the Prisoner of Azkaban.txt\", \"harry/04 Harry Potter and the Goblet of Fire.txt\", \"harry/05 Harry Potter and the Order of the Phoenix.txt\", \"harry/06 Harry Potter and the Half-Blood Prince.txt\", \"harry/07 Harry Potter and the Deathly Hallows.txt\"]\n",
    "filenames_list2 = [\"alice/alice.txt\"]\n",
    "\n",
    "filenames_list = filenames_list + filenames_list2\n",
    "\n",
    "for filename in filenames_list:\n",
    "    clean_text(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 토큰화\n",
    "\n",
    "UTF-8 BPE(Bype Pair Encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "글자수: 26 토큰수 6\n",
      "[18308, 14179, 373, 257, 18731, 13]\n",
      "Harry Potter was a wizard.\n",
      "18308\t -> Harry\n",
      "14179\t ->  Potter\n",
      "373\t ->  was\n",
      "257\t ->  a\n",
      "18731\t ->  wizard\n",
      "13\t -> .\n"
     ]
    }
   ],
   "source": [
    "import tiktoken # pip install tiktoken\n",
    "\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "text = \"Harry Potter was a wizard.\"\n",
    "\n",
    "tokens = tokenizer.encode(text)\n",
    "\n",
    "print(\"글자수:\", len(text), \"토큰수\", len(tokens))\n",
    "print(tokens)\n",
    "print(tokenizer.decode(tokens))\n",
    "for t in tokens:\n",
    "    print(f\"{t}\\t -> {tokenizer.decode([t])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import AutoTokenizer # pip install transformers\n",
    "\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"LGAI-EXAONE/EXAONE-3.5-7.8B-Instruct\")  # KoGPT2 사용\n",
    "# # tokenizer = AutoTokenizer.from_pretrained(\"skt/kogpt2-base-v2\")  # KoGPT2 사용\n",
    "\n",
    "# print(\"Vocab size :\", len(tokenizer))\n",
    "\n",
    "# text = \"대사께서는 도(道)를 얻은 모양이구려.\"\n",
    "\n",
    "# tokens = tokenizer.encode(text)\n",
    "\n",
    "# print(len(text), len(tokens))\n",
    "# print(tokens)\n",
    "# print(tokenizer.decode(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H -> [39] -> H\n",
      "a -> [64] -> a\n",
      "r -> [81] -> r\n",
      "r -> [81] -> r\n",
      "y -> [88] -> y\n",
      "  -> [220] ->  \n",
      "P -> [47] -> P\n",
      "o -> [78] -> o\n",
      "t -> [83] -> t\n",
      "t -> [83] -> t\n",
      "e -> [68] -> e\n",
      "r -> [81] -> r\n",
      "  -> [220] ->  \n",
      "w -> [86] -> w\n",
      "a -> [64] -> a\n",
      "s -> [82] -> s\n",
      "  -> [220] ->  \n",
      "a -> [64] -> a\n",
      "  -> [220] ->  \n",
      "w -> [86] -> w\n",
      "i -> [72] -> i\n",
      "z -> [89] -> z\n",
      "a -> [64] -> a\n",
      "r -> [81] -> r\n",
      "d -> [67] -> d\n",
      ". -> [13] -> .\n"
     ]
    }
   ],
   "source": [
    "for char in text:\n",
    "    token_ids = tokenizer.encode(char)     # 한 글자씩 인코딩(토큰화)\n",
    "    decoded = tokenizer.decode(token_ids)  # 한 글자씩 디코딩\n",
    "    print(f\"{char} -> {token_ids} -> {decoded}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 데이터로더(DataLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of tokens in txt: 130520\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, txt, max_length, stride):\n",
    "        self.input_ids = []\n",
    "        self.target_ids = []\n",
    "\n",
    "        # token_ids = tokenizer.encode(\"<|endoftext|>\" + txt, allowed_special={\"<|endoftext|>\"})\n",
    "        token_ids = tokenizer.encode(txt)\n",
    "\n",
    "        print(\"# of tokens in txt:\", len(token_ids))\n",
    "\n",
    "        for i in range(0, len(token_ids) - max_length, stride):\n",
    "            input_chunk = token_ids[i:i + max_length]\n",
    "            target_chunk = token_ids[i + 1: i + max_length + 1]\n",
    "            self.input_ids.append(torch.tensor(input_chunk))\n",
    "            self.target_ids.append(torch.tensor(target_chunk))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.input_ids[idx], self.target_ids[idx]\n",
    "\n",
    "# with open(\"cleaned_한글문서.txt\", 'r', encoding='utf-8-sig') as file: # 선택: -sig를 붙여서 BOM 제거\n",
    "with open(\"harry/02 Harry Potter and the Chamber of Secrets.txt_cleaned\", 'r', encoding='utf-8-sig') as file: # 선택: -sig를 붙여서 BOM 제거\n",
    "    txt = file.read()\n",
    "\n",
    "dataset = MyDataset(txt, max_length = 32, stride = 4)\n",
    "\n",
    "train_loader = DataLoader(dataset, batch_size=128, shuffle=True, drop_last=True)\n",
    "\n",
    "# 주의: 여기서는 코드를 단순화하기 위해 test, valid는 생략하고 train_loader만 만들었습니다.\n",
    "#      관련된 ML 이론이 궁금하신 분들은 train vs test vs validation 등으로 검색해보세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " still putting up a terrific fight. “Stand back,” said Lockhart, who was rolling up his jade-green sleeves. “No\n",
      " putting up a terrific fight. “Stand back,” said Lockhart, who was rolling up his jade-green sleeves. “No —\n"
     ]
    }
   ],
   "source": [
    "dataiter = iter(train_loader)\n",
    "\n",
    "x, y = next(dataiter)\n",
    "\n",
    "print(tokenizer.decode(x[0].tolist()))\n",
    "print(tokenizer.decode(y[0].tolist()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 뉴럴네트워크 모델 정의\n",
    "\n",
    "모델 정의는 교재 \"[Build a Large Language Model (From Scratch)](https://www.manning.com/books/build-a-large-language-model-from-scratch)\"에서 제공하는 [예제 코드](https://github.com/rasbt/LLMs-from-scratch)를 약간 수정하였습니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델을 정의할 때 사용하는 상수들\n",
    "\n",
    "VOCAB_SIZE = tokenizer.n_vocab # 50257 Tiktoken\n",
    "#VOCAB_SIZE = len(tokenizer) # AutoTokenizer\n",
    "CONTEXT_LENGTH = 128  # Shortened context length (orig: 1024)\n",
    "EMB_DIM = 768  # Embedding dimension\n",
    "NUM_HEADS = 12  # Number of attention heads\n",
    "NUM_LAYERS = 12  # Number of layers\n",
    "DROP_RATE = 0.1  # Dropout rate\n",
    "QKV_BIAS = False  # Query-key-value bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_in, d_out):\n",
    "        super().__init__()\n",
    "        \n",
    "        assert d_out % NUM_HEADS == 0, \"d_out must be divisible by n_heads\"\n",
    "\n",
    "        self.d_out = d_out\n",
    "        self.head_dim = d_out // NUM_HEADS\n",
    "\n",
    "        self.W_query = nn.Linear(d_in, d_out, bias=QKV_BIAS)\n",
    "        self.W_key = nn.Linear(d_in, d_out, bias=QKV_BIAS)\n",
    "        self.W_value = nn.Linear(d_in, d_out, bias=QKV_BIAS)\n",
    "        self.out_proj = nn.Linear(d_out, d_out)\n",
    "        self.dropout = nn.Dropout(DROP_RATE)\n",
    "        self.register_buffer('mask', torch.triu(torch.ones(CONTEXT_LENGTH, CONTEXT_LENGTH), diagonal=1))\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, num_tokens, d_in = x.shape\n",
    "\n",
    "        keys = self.W_key(x)  # (b, num_tokens, d_out)\n",
    "        queries = self.W_query(x)\n",
    "        values = self.W_value(x)\n",
    "\n",
    "        keys = keys.view(b, num_tokens, NUM_HEADS, self.head_dim)\n",
    "        values = values.view(b, num_tokens, NUM_HEADS, self.head_dim)\n",
    "        queries = queries.view(b, num_tokens, NUM_HEADS, self.head_dim)\n",
    "\n",
    "        keys = keys.transpose(1, 2)\n",
    "        queries = queries.transpose(1, 2)\n",
    "        values = values.transpose(1, 2)\n",
    "\n",
    "        attn_scores = queries @ keys.transpose(2, 3)\n",
    "\n",
    "        mask_bool = self.mask.bool()[:num_tokens, :num_tokens]\n",
    "\n",
    "        attn_scores.masked_fill_(mask_bool, -torch.inf)\n",
    "\n",
    "        attn_weights = torch.softmax(attn_scores / keys.shape[-1]**0.5, dim=-1)\n",
    "        attn_weights = self.dropout(attn_weights)\n",
    "\n",
    "        context_vec = (attn_weights @ values).transpose(1, 2)\n",
    "\n",
    "        context_vec = context_vec.reshape(b, num_tokens, self.d_out)\n",
    "        context_vec = self.out_proj(context_vec)\n",
    "\n",
    "        return context_vec\n",
    "\n",
    "class LayerNorm(nn.Module):\n",
    "    def __init__(self, emb_dim):\n",
    "        super().__init__()\n",
    "        self.eps = 1e-5\n",
    "        self.scale = nn.Parameter(torch.ones(emb_dim))\n",
    "        self.shift = nn.Parameter(torch.zeros(emb_dim))\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean = x.mean(dim=-1, keepdim=True)\n",
    "        var = x.var(dim=-1, keepdim=True, unbiased=False)\n",
    "        norm_x = (x - mean) / torch.sqrt(var + self.eps)\n",
    "        return self.scale * norm_x + self.shift\n",
    "\n",
    "class GELU(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return 0.5 * x * (1 + torch.tanh(\n",
    "            torch.sqrt(torch.tensor(2.0 / torch.pi)) *\n",
    "            (x + 0.044715 * torch.pow(x, 3))\n",
    "        ))\n",
    "\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(EMB_DIM, 4 * EMB_DIM),\n",
    "            GELU(),\n",
    "            nn.Linear(4 * EMB_DIM, EMB_DIM),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "\n",
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.att = MultiHeadAttention(\n",
    "            d_in=EMB_DIM,\n",
    "            d_out=EMB_DIM)\n",
    "    \n",
    "        self.ff = FeedForward()\n",
    "        self.norm1 = LayerNorm(EMB_DIM)\n",
    "        self.norm2 = LayerNorm(EMB_DIM)\n",
    "        self.drop_shortcut = nn.Dropout(DROP_RATE)\n",
    "\n",
    "    def forward(self, x):\n",
    "        shortcut = x\n",
    "        x = self.norm1(x)\n",
    "        x = self.att(x)\n",
    "        x = self.drop_shortcut(x)\n",
    "        x = x + shortcut\n",
    "\n",
    "        shortcut = x\n",
    "        x = self.norm2(x)\n",
    "        x = self.ff(x)\n",
    "        x = self.drop_shortcut(x)\n",
    "        x = x + shortcut\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class GPTModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.tok_emb = nn.Embedding(VOCAB_SIZE, EMB_DIM)\n",
    "        self.pos_emb = nn.Embedding(CONTEXT_LENGTH, EMB_DIM)\n",
    "        self.drop_emb = nn.Dropout(DROP_RATE)\n",
    "\n",
    "        self.trf_blocks = nn.Sequential(\n",
    "            *[TransformerBlock() for _ in range(NUM_LAYERS)])\n",
    "\n",
    "        self.final_norm = LayerNorm(EMB_DIM)\n",
    "        self.out_head = nn.Linear(EMB_DIM, VOCAB_SIZE, bias=False)\n",
    "\n",
    "    def forward(self, in_idx):\n",
    "        batch_size, seq_len = in_idx.shape\n",
    "        tok_embeds = self.tok_emb(in_idx)\n",
    "        pos_embeds = self.pos_emb(torch.arange(seq_len, device=in_idx.device))\n",
    "        x = tok_embeds + pos_embeds  # Shape [batch_size, num_tokens, emb_size]\n",
    "        x = self.drop_emb(x)\n",
    "        x = self.trf_blocks(x)\n",
    "        x = self.final_norm(x)\n",
    "        logits = self.out_head(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 훈련"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "#device = \"cpu\"\n",
    "print(device)\n",
    "\n",
    "torch.manual_seed(123)\n",
    "model = GPTModel()\n",
    "model.to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.0004, weight_decay=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens seen: 4096\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 17\u001b[39m\n\u001b[32m     15\u001b[39m epoch_loss += loss.item()\n\u001b[32m     16\u001b[39m loss.backward() \u001b[38;5;66;03m# Calculate loss gradients\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m \u001b[43moptimizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# Update model weights using loss gradients\u001b[39;00m\n\u001b[32m     18\u001b[39m tokens_seen += input_batch.numel()\n\u001b[32m     19\u001b[39m global_step += \u001b[32m1\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/deep/lib/python3.12/site-packages/torch/optim/optimizer.py:485\u001b[39m, in \u001b[36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    480\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    481\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m    482\u001b[39m                 \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    483\u001b[39m             )\n\u001b[32m--> \u001b[39m\u001b[32m485\u001b[39m out = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    486\u001b[39m \u001b[38;5;28mself\u001b[39m._optimizer_step_code()\n\u001b[32m    488\u001b[39m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/deep/lib/python3.12/site-packages/torch/optim/optimizer.py:79\u001b[39m, in \u001b[36m_use_grad_for_differentiable.<locals>._use_grad\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     77\u001b[39m     torch.set_grad_enabled(\u001b[38;5;28mself\u001b[39m.defaults[\u001b[33m\"\u001b[39m\u001b[33mdifferentiable\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m     78\u001b[39m     torch._dynamo.graph_break()\n\u001b[32m---> \u001b[39m\u001b[32m79\u001b[39m     ret = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     80\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m     81\u001b[39m     torch._dynamo.graph_break()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/deep/lib/python3.12/site-packages/torch/optim/adam.py:246\u001b[39m, in \u001b[36mAdam.step\u001b[39m\u001b[34m(self, closure)\u001b[39m\n\u001b[32m    234\u001b[39m     beta1, beta2 = group[\u001b[33m\"\u001b[39m\u001b[33mbetas\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m    236\u001b[39m     has_complex = \u001b[38;5;28mself\u001b[39m._init_group(\n\u001b[32m    237\u001b[39m         group,\n\u001b[32m    238\u001b[39m         params_with_grad,\n\u001b[32m   (...)\u001b[39m\u001b[32m    243\u001b[39m         state_steps,\n\u001b[32m    244\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m246\u001b[39m     \u001b[43madam\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    247\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    248\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    249\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    250\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    251\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    252\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    253\u001b[39m \u001b[43m        \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mamsgrad\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    254\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    255\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    256\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    257\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlr\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    258\u001b[39m \u001b[43m        \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mweight_decay\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    259\u001b[39m \u001b[43m        \u001b[49m\u001b[43meps\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43meps\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    260\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmaximize\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    261\u001b[39m \u001b[43m        \u001b[49m\u001b[43mforeach\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mforeach\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    262\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcapturable\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    263\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdifferentiable\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    264\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfused\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfused\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    265\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mgrad_scale\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    266\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfound_inf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    267\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdecoupled_weight_decay\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdecoupled_weight_decay\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    268\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    270\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/deep/lib/python3.12/site-packages/torch/optim/optimizer.py:147\u001b[39m, in \u001b[36m_disable_dynamo_if_unsupported.<locals>.wrapper.<locals>.maybe_fallback\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    145\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m disabled_func(*args, **kwargs)\n\u001b[32m    146\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m147\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/deep/lib/python3.12/site-packages/torch/optim/adam.py:933\u001b[39m, in \u001b[36madam\u001b[39m\u001b[34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, has_complex, decoupled_weight_decay, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[39m\n\u001b[32m    930\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    931\u001b[39m     func = _single_tensor_adam\n\u001b[32m--> \u001b[39m\u001b[32m933\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    934\u001b[39m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    935\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    936\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    937\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    938\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    939\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    940\u001b[39m \u001b[43m    \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[43m=\u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    941\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    942\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    943\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    944\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    945\u001b[39m \u001b[43m    \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[43m=\u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    946\u001b[39m \u001b[43m    \u001b[49m\u001b[43meps\u001b[49m\u001b[43m=\u001b[49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    947\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    948\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcapturable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    949\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    950\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    951\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    952\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdecoupled_weight_decay\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecoupled_weight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    953\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/deep/lib/python3.12/site-packages/torch/optim/adam.py:456\u001b[39m, in \u001b[36m_single_tensor_adam\u001b[39m\u001b[34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, has_complex, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable, decoupled_weight_decay)\u001b[39m\n\u001b[32m    454\u001b[39m         exp_avg_sq.mul_(beta2).addcmul_(grad, grad, value=\u001b[32m1\u001b[39m - beta2)\n\u001b[32m    455\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m456\u001b[39m     \u001b[43mexp_avg_sq\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmul_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m)\u001b[49m.addcmul_(grad, grad, value=\u001b[32m1\u001b[39m - beta2)\n\u001b[32m    458\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m capturable \u001b[38;5;129;01mor\u001b[39;00m differentiable:\n\u001b[32m    459\u001b[39m     step = step_t\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "tokens_seen, global_step = 0, -1\n",
    "\n",
    "losses = []\n",
    "\n",
    "for epoch in range(100):\n",
    "    model.train()  # Set model to training mode\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    for input_batch, target_batch in train_loader:\n",
    "        optimizer.zero_grad() # Reset loss gradients from previous batch iteration\n",
    "        input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
    "\n",
    "        logits = model(input_batch)\n",
    "        loss = torch.nn.functional.cross_entropy(logits.flatten(0, 1), target_batch.flatten())\n",
    "        epoch_loss += loss.item()\n",
    "        loss.backward() # Calculate loss gradients\n",
    "        optimizer.step() # Update model weights using loss gradients\n",
    "        tokens_seen += input_batch.numel()\n",
    "        global_step += 1\n",
    "\n",
    "        if global_step % 1000 == 0:\n",
    "            print(f\"Tokens seen: {tokens_seen}\")\n",
    "        # Optional evaluation step\n",
    "\n",
    "    avg_loss = epoch_loss / len(train_loader)\n",
    "    losses.append(avg_loss)\n",
    "    print(f\"Epoch: {epoch + 1}, Loss: {avg_loss}\")\n",
    "    torch.save(model.state_dict(), \"model_\" + str(epoch + 1).zfill(3) + \".pth\")\n",
    "\n",
    "# 주의: 여기서는 편의상 모든 데이터를 train에 사용하였습니다. \n",
    "#      ML에서는 일부 데이터를 validation에 사용하는 것이 일반적입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(losses)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Loss Over Epochs')\n",
    "plt.show()\n",
    "\n",
    "# 보충: validation loss를 같이 그려서 비교하는 사례 https://www.geeksforgeeks.org/training-and-validation-loss-in-deep-learning/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 결과 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(128, 768)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 파일로 저장했던 네트워크의 가중치들 읽어들이기\n",
    "model.load_state_dict(torch.load(\"model_100.pth\", map_location=device, weights_only=True))\n",
    "model.eval() # dropout을 사용하지 않음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.15\t 973\t  used\n",
      "11.10\t 550\t  had\n",
      "11.04\t 1479\t  free\n",
      "10.70\t 257\t  a\n",
      "10.31\t 1541\t  already\n",
      "9.09\t 4978\t  caught\n",
      "8.91\t 0\t !\n",
      "8.87\t 2982\t  heard\n",
      "8.61\t 460\t  can\n",
      "8.40\t 4084\t  clearly\n",
      " used\n"
     ]
    }
   ],
   "source": [
    "idx = tokenizer.encode(\"Dobby is\") # 토큰 id의 list\n",
    "idx = torch.tensor(idx).unsqueeze(0).to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    logits = model(idx)\n",
    "\n",
    "logits = logits[:, -1, :]\n",
    "\n",
    "# 가장 확률이 높은 단어 10개 출력\n",
    "top_logits, top_indices = torch.topk(logits, 10) \n",
    "for p, i in zip(top_logits.squeeze(0).tolist(), top_indices.squeeze(0).tolist()):\n",
    "    print(f\"{p:.2f}\\t {i}\\t {tokenizer.decode([i])}\")\n",
    "\n",
    "# 가장 확률이 높은 단어 출력\n",
    "idx_next = torch.argmax(logits, dim=-1, keepdim=True)\n",
    "flat = idx_next.squeeze(0) # 배치 차원 제거 torch.Size([1])\n",
    "out = tokenizer.decode(flat.tolist()) # 텐서를 리스트로 바꿔서 디코드\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(model, idx, max_new_tokens, context_size, temperature=0.0, top_k=None, eos_id=None):\n",
    "\n",
    "    for _ in range(max_new_tokens):\n",
    "        idx_cond = idx[:, -context_size:]\n",
    "        with torch.no_grad():\n",
    "            logits = model(idx_cond)\n",
    "        logits = logits[:, -1, :]\n",
    "\n",
    "        if top_k is not None:\n",
    "            top_logits, _ = torch.topk(logits, top_k)\n",
    "            min_val = top_logits[:, -1]\n",
    "            logits = torch.where(logits < min_val, torch.tensor(float(\"-inf\")).to(logits.device), logits)\n",
    "\n",
    "        if temperature > 0.0:\n",
    "            logits = logits / temperature\n",
    "            probs = torch.softmax(logits, dim=-1)  # (batch_size, context_len)\n",
    "            idx_next = torch.multinomial(probs, num_samples=1)  # (batch_size, 1)\n",
    "        else:\n",
    "            idx_next = torch.argmax(logits, dim=-1, keepdim=True)  # (batch_size, 1)\n",
    "\n",
    "        if idx_next == eos_id:\n",
    "            break\n",
    "\n",
    "        idx = torch.cat((idx, idx_next), dim=1)  # (batch_size, num_tokens+1)\n",
    "\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 : Dobby is had to punish himself, sir,” said the elf, who had gone slightly cross-eyed. “Dobby almost spoke ill of his family, sir, sir, sir, sir, sir, sir, sir, sir, sir,\n",
      "1 : Dobby is had to punish himself, sir,” said the elf, who had gone slightly cross-eyed. “Dobby almost spoke ill of his family, sir. Dobby can’s family, sir, sir, sir, Dobby\n",
      "2 : Dobby is a house-elf.…” said Harry. “Well, whoever owns him will be an old wizarding family, and they’ll be rich, too keen to bew-blood mother died —’ll bewitching\n",
      "3 : Dobby is had to punish himself, sir,” said the elf, who had gone slightly cross-eyed. “Dobby almost spoke ill of his family, sir, sir, sir, sir, sir, sir, sir,’s family\n",
      "4 : Dobby is used to death threats and the best plan we’ve got, so full steam ahead, I say.” However, while Hermione was checking that the bo up and checking his wand id sorry for a Gryffindor Tower, they didn\n",
      "5 : Dobby is a house-elf.…” said Harry. “Well, whoever owns him will be an old wizarding family, and they’ll be rich, too…’ll bewitched Defense Against the evening…’ll\n",
      "6 : Dobby is?” “Locked in the cupboard under the stairs, and I can’t get out of this room —” “No one of this time out of you’ll ever understood where I’s powers\n",
      "7 : Dobby is free.” Lucius Malfoy ripped the sock off the diary, threw it aside, then looked furiously from the ruined book to Harry.”You’ll need ter just heard concern,’ll meet the Weasleys if you�\n",
      "8 : Dobby is used to death threats and. The cat-flap rattled and Aunt Petunias hand appeared, pushing a bowl of canned soup into the room. Harry’s room. Harry, whose insides, and fell: a corner, which knocked\n",
      "9 : Dobby is had to punish himself, sir,” said the elf, who had gone slightly cross-eyed. “Dobby almost spoke ill of his family, sir, sir, sir, sir, sir, sir, sir,’s family\n"
     ]
    }
   ],
   "source": [
    "start_context = input(\"Start context: \")\n",
    "\n",
    "# idx = tokenizer.encode(start_context, allowed_special={'<|endoftext|>'})\n",
    "idx = tokenizer.encode(start_context)\n",
    "idx = torch.tensor(idx).unsqueeze(0)\n",
    "\n",
    "context_size = model.pos_emb.weight.shape[0] \n",
    "\n",
    "for i in range(10):\n",
    "\n",
    "    token_ids = generate(\n",
    "        model=model,\n",
    "        idx=idx.to(device),\n",
    "        max_new_tokens=50,\n",
    "        context_size= context_size,\n",
    "        top_k=50,\n",
    "        temperature=0.5\n",
    "    )\n",
    "\n",
    "    flat = token_ids.squeeze(0) # remove batch dimension\n",
    "    out = tokenizer.decode(flat.tolist()).replace(\"\\n\", \" \")\n",
    "\n",
    "    print(i, \":\", out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 보충\n",
    "\n",
    "- 여기서 소개해드린 LLM은 한 단어씩 만들어 가는 **자동회귀(autoregressive)** LLM 이라고 합니다. (자가회귀로 번역하기도 합니다.) \n",
    "- 최근에는 **디퓨전(Diffusion)** LLM 기술도 나오기 시작했습니다. 한번에 한 단어씩이 아니라 전체를 생성합니다. ([참고1](https://x.com/karpathy/status/1894923254864978091), [참고2](https://x.com/omarsar0/status/1891568386494300252))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
